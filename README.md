# qwen-image-app

**âš ï¸ EXPERIMENTAL** - Hacky text-to-image generation playground built around Qwen-Image model. Lots of stuff is broken, everything will change multiple times, don't get attached to anything!

## ğŸš§ What This Is

ğŸ¨ **Text-to-Image Generation** - Basic generation with weird image transformation features
ğŸ¤– **Multimodal Chat** - VL model conversation that sometimes works
ğŸ“ **External Templates** - File-based prompts because why not
ğŸ–¼ï¸ **Gallery Thing** - Browse generated images if they don't crash
âš¡ **Multi-GPU Stuff** - Tries to use multiple GPUs, results may vary
ğŸ”§ **Component Loading** - Load/unload model pieces individually

**This is a personal experimentation platform for exploring Qwen-Image capabilities. Features are half-implemented, APIs will change, stuff will break. You've been warned!**

[ğŸ“‹ **See Full Feature List â†’**](FEATURES.md)

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
# Clone and setup
git clone <repository-url>
cd qwen-image-app

# Make go.sh executable and run (handles installation automatically)
chmod +x go.sh
./go.sh
```

### 2. Configure Models
```bash
# Create symlinks for models and LoRAs (recommended)
ln -s ~/models ./models
ln -s ~/loras ./loras

# Edit config.yaml with your model paths
nano config.yaml
```

### 3. Launch Application
```bash
# Start GUI
./go.sh
```

Access at: http://localhost:7860

## ğŸ—ï¸ Architecture

### Core Components
```
src/                    # Business Logic
â”œâ”€â”€ config.py          # YAML configuration management
â”œâ”€â”€ models.py          # Multi-GPU model management
â”œâ”€â”€ process.py         # Generation pipeline
â”œâ”€â”€ chat.py            # VL model chat interface
â”œâ”€â”€ gallery.py         # Session and image management
â”œâ”€â”€ prompt.py          # Template processing & enhancement
â”œâ”€â”€ metadata.py        # PNG metadata embedding
â”œâ”€â”€ analysis.py        # Text encoder analysis tools
â””â”€â”€ edit.py            # Img2img utilities

app/                    # Gradio UI
â”œâ”€â”€ app.py             # Main application entry
â”œâ”€â”€ generate.py        # Image generation interface
â”œâ”€â”€ chat.py            # Chat interface with interactions
â”œâ”€â”€ gallery.py         # Gallery browser
â”œâ”€â”€ models.py          # Model management controls
â””â”€â”€ config.py          # Configuration editor

templates/              # External Templates
â”œâ”€â”€ system.txt         # Chat system prompt
â”œâ”€â”€ image.txt          # Generation template
â”œâ”€â”€ enhancement.txt    # Prompt enhancement (EN)
â”œâ”€â”€ enhancement_zh.txt # Prompt enhancement (ZH)
â””â”€â”€ describe.txt       # Image-to-prompt template
```

### Template System
All prompts are externalized for easy customization:
- **Hot-reloadable** - No restart required
- **Language-aware** - Automatic Chinese/English detection
- **Professional** - Expert-crafted for optimal results
- **File-based** - Easy editing and version control

## âš™ï¸ Configuration

### Essential Settings
Edit `config.yaml` with your setup:

```yaml
# Model Locations
model_diffusion: "~/models/Qwen-Image"
model_text_encoder: "~/models/Qwen2.5-VL-7B-Instruct-abliterated"
model_vae: "~/models/Qwen-Image/vae"

# GPU Distribution (example for 5-GPU setup)
gpu_text_encoder: "3:8GiB,4:16GiB"        # VL model on GPUs 3,4
gpu_transformer: "0:13GiB,1:13GiB,2:15.5GiB"  # Diffusion on GPUs 0,1,2
gpu_vae: "cuda:3"                          # VAE on GPU 3

# Features
auto_load_pipeline: true     # Load models on startup
enable_lora: true           # Enable LoRA adapters
enable_metadata_embed: true # Save parameters in images
```

[ğŸ“– **Full Configuration Guide â†’**](docs/configuration.md)

## ğŸ¯ Usage Examples

### Interface Tabs
- **ğŸ¨ Generate** - Main image creation with two-stage and img2img options
- **ğŸ–¼ï¸ Gallery** - Browse images by session with metadata extraction
- **ğŸ’¬ Chat** - VL model conversation with image upload and message interactions
- **ğŸ”¬ Analysis** - Text encoder comparison and token analysis tools
- **ğŸ”§ Models** - Component loading controls with real-time status
- **âš™ï¸ Config** - Live YAML configuration editor

### Multimodal Chat Features
**Message Controls:**
- **Edit** - Click any message to modify (yours or assistant's)
- **Retry** - Regenerate responses from any point
- **Undo** - Remove messages with content recovery
- **Copy** - One-click message copying

**Image Analysis:**
- **Upload & Discuss** - Images appear inline with context preservation
- **Describe for Generation** - Get professional prompts from uploaded images
- **Reverse Engineering** - Analyze composition, lighting, and style

### Generation Modes
```bash
# Basic text-to-image
prompt: "mountain landscape"
â†’ Maybe enable "Add Quality Enhancement" if you're feeling lucky
â†’ Click "Enhance" for AI-improved prompts (when it works)

# Noise Interpolation (image transformation)
â†’ Upload input image
â†’ Crank strength to 0.99 for maximum transformation
â†’ Generate with different prompt for creative results

# Two-stage generation (experimental)
â†’ Set "Second Stage Steps" > 0
â†’ Stage 1 makes base image
â†’ Stage 2 applies noise interpolation transformation
```

### Session Workflow
```bash
# Organize by project
http://localhost:7860/?session=character-designs

# Or use date-based (automatic)
http://localhost:7860/?session=2024-01-15

# Gallery shows all session images with metadata
```

## ğŸ’¾ Model Requirements

### Qwen-Image Model Family
Download required models and update paths in `config.yaml`:

| Component | Size | Purpose |
|-----------|------|---------|
| **Qwen-Image** | ~40GB | Main diffusion transformer |
| **Qwen2.5-VL-7B** | ~15GB | Vision-language model for chat |
| **QwenImageVAE** | ~250MB | Image encoder/decoder |
| **Tokenizer** | ~2MB | Text tokenization |
| **Scheduler** | ~1KB | Flow matching scheduler |

### GPU Memory Requirements
**Minimum:** 24GB total VRAM (single GPU)
**Recommended:** 48GB+ VRAM (multi-GPU)

**Example Distributions:**
```bash
# 5-GPU Setup (RTX 4090s)
GPU 0,1,2: Transformer (13GB each)
GPU 3: Text Encoder + VAE (8GB)
GPU 4: Text Encoder (16GB)

# 2-GPU Setup (RTX 4090s)
GPU 0: Transformer + VL model (24GB)
GPU 1: Transformer overflow (20GB)
```

## ğŸ”§ Performance Tips

### GPU Optimization
- **Multi-GPU Distribution** - Spread models across available GPUs
- **Memory Management** - Configure per-component VRAM limits
- **VAE Tiling** - Enable for large image generation
- **Auto-Loading** - Pre-load models on startup

### Generation Speed
- **Component Loading** - Load only needed components
- **Batch Processing** - Use queue system for multiple images
- **Step Optimization** - Adjust steps based on quality needs
- **Template Caching** - Templates cached after first load

## ğŸ› ï¸ Installation

### System Requirements
- **Python:** 3.10+
- **CUDA:** 12.1+ with compatible drivers
- **GPU:** 24GB+ VRAM total (multi-GPU recommended)
- **RAM:** 16GB+ system memory
- **Storage:** 100GB+ for models

### Quick Install
```bash
# Clone repository
git clone <repository-url>
cd qwen-image-app

# Install with automated script
chmod +x scripts/install.sh
./scripts/install.sh

# Activate environment
source .venv/bin/activate
```

### Verification
```bash
# Test installation
./scripts/test.sh

# Check GPU setup
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}')"
```

## ğŸ”§ Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **CUDA Out of Memory** | Adjust GPU allocation in config, enable VAE tiling |
| **Models Not Loading** | Check paths in config.yaml, verify model files exist |
| **Slow Generation** | Balance GPU allocation, disable unused features |
| **Template Errors** | Verify template files exist in `./templates/` directory |
| **Chat Not Working** | Ensure VL model loaded, check processor status |
| **Queue Stuck** | Check Models tab for component status |

### Performance Issues
```bash
# Check GPU memory usage
nvidia-smi

# Monitor component loading
# â†’ Models tab â†’ "Refresh Status"

# Verify template loading
ls -la templates/
```

### Getting Help
1. ğŸ“‹ Check [FEATURES.md](FEATURES.md) for complete capabilities
2. ğŸ” Review configuration examples above
3. ğŸ› Test with `./scripts/test.sh`
4. ğŸ’¬ Open GitHub issue with logs and system info

## ğŸš€ Development

### Project Structure
- **Clean Architecture** - Business logic (`src/`) separated from UI (`app/`)
- **Modular Design** - Each feature as independent module
- **External Templates** - All prompts in editable files
- **Test Coverage** - Comprehensive test suite in `./tests/`

### Contributing
```bash
# Run tests before submitting
./scripts/test.sh

# Follow existing code patterns
# Add tests for new features
# Update documentation
```

## ğŸ“„ License

[License TBD]

## ğŸ™ Credits

- **Qwen-Image** - Alibaba Cloud's text-to-image model
- **Qwen2.5-VL** - Multimodal vision-language model
- **Diffusers** - HuggingFace's diffusion model library
- **Gradio** - Web interface framework

---

**Star â­ this repo if you find it useful!**
